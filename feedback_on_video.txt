Germans Savcisens
18 Hours ago 4:12 PM
I like the setup and idea for the project:

1. You have quite a lot of samples in the data - you may downsample it to save some time on computations. 

2. Do not forget to describe how data is collected and what potential issues are there. Also, describe the algorithm as it is a crucial part of your project. 

3. I am unsure how many protected groups there are (or how many you plan to use). You might want to do a Fairness Evaluation to find the groups with the worst performance and focus exclusively on them.

4. Argue for the choice of the Fairness metric (and performance metric if you account for it in the report).

5. When it comes to SHAP - it is an interesting approach. You can also look at the saliency maps (look at the Captum package) - it allows you to see where does the model pays attention. So you might pick an image where it misclassifies and an image where it provides a correct classification (identification) and see how these maps are different. 

6. You can also look at the intersectional groups. I am not sure what kind of protected attributes you have in there, but basically, it means that you look at the performance of the model for African-American Women, African-American Men, and so forth. So it might provide additional depth to the analysis. 

7. Data augmentation is also interesting - you can try to add some noise or object to images and see what happens there in terms of prediction (aka how robust the algorithm is to different kinds of noise). Again, though, in case you go with this - please argue why it is important to have a robust algorithm.